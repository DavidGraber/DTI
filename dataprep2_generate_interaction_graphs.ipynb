{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "affinity_dict = load_object('./PDBbind_affinity_dict.pkl')\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('PDBbind_data_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(affinity_dict, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "# RDKit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdPartialCharges\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize  \n",
    "\n",
    "from time import time\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "\n",
    "from f_parse_pdb_general import parse_pdb\n",
    "\n",
    "# PyTorch and PyTorch Geometric\n",
    "import torch\n",
    "from torch_geometric.utils import to_undirected, add_self_loops\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def arg_parser():\n",
    "#     parser = argparse.ArgumentParser(description=\"Inputs to Graph Generation Script\")\n",
    "#     parser.add_argument('--data_dir', type=str, required=True, help='Path to the data directory containing all proteins(PDB) and ligands (SDF)')\n",
    "#     parser.add_argument('--affinity_dict', type=str, required=True, help='Path to json file assigning affinity values to complexes in the data')\n",
    "    \n",
    "#     parser.add_argument('--embedding_descriptors',\n",
    "#     nargs='+',\n",
    "#     help='Provide names of embeddings that should be incorporated (--embedding_descriptors string1 string2 string3)')\n",
    "\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# args = arg_parser()\n",
    "# data_dir = args.data_dir\n",
    "# affinity_dict_path = args.affinity_dict\n",
    "# embedding_descriptors = args.embedding_descriptors\n",
    "\n",
    "### For testing ###\n",
    "affinity_dict_path = 'PDBbind_data_dict.json'\n",
    "data_dir = 'PDBbind1'\n",
    "embedding_descriptors = ['ChemBERTa-10M-MLM', 'ankh_base', 'esm2_t6_8M_UR50D']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sdf_file(file_path):\n",
    "    suppl = Chem.SDMolSupplier(file_path, sanitize = True, removeHs=True, strictParsing=True)\n",
    "    molecules = []\n",
    "    for mol in suppl:\n",
    "        if mol is not None:\n",
    "            molecules.append(mol)\n",
    "    return molecules\n",
    "\n",
    "\n",
    "def compute_connections(protein_atomcoords, pos):\n",
    "    diff = protein_atomcoords[np.newaxis, :, :] - pos[:, np.newaxis, :]\n",
    "    pairwise_distances = np.linalg.norm(diff, axis=2)\n",
    "    close = pairwise_distances <= 5\n",
    "    return close\n",
    "compute_connections = jit(compute_connections)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\n",
    "    Unlike `one_of_k_encoding`, if `x` is not in `allowable_set`, this method\n",
    "    pretends that `x` is the last element of `allowable_set`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: object\n",
    "        Must be present in `allowable_set`.\n",
    "    allowable_set: list\n",
    "        List of allowable quantities.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> dc.feat.graph_features.one_of_k_encoding_unk(\"s\", [\"a\", \"b\", \"c\"])\n",
    "    [False, False, True]\n",
    "    \"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    \"\"\"Encodes elements of a provided set as integers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: object\n",
    "        Must be present in `allowable_set`.\n",
    "    allowable_set: list\n",
    "        List of allowable quantities.\n",
    "    Example\n",
    "    -------\n",
    "    >>> import deepchem as dc\n",
    "    >>> dc.feat.graph_features.one_of_k_encoding(\"a\", [\"a\", \"b\", \"c\"])\n",
    "    [True, False, False]\n",
    "    Raises\n",
    "    ------\n",
    "    `ValueError` if `x` is not in `allowable_set`.\n",
    "    \"\"\"\n",
    "    if x not in allowable_set:\n",
    "        raise ValueError(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "\n",
    "def make_undirected_with_self_loops(edge_index, edge_attr, undirected = True, self_loops = True):\n",
    "\n",
    "    self_loop_feature_vector = torch.tensor(   [0., 1., 0.,                         # it's a self-loop\n",
    "                                                0,                                  # length is zero\n",
    "                                                0., 0., 0.,0.,0.,                   # bondtype = None\n",
    "                                                0.,                                 # is not conjugated\n",
    "                                                0.,                                 # is not in ring\n",
    "                                                0., 0., 0., 0., 0., 0.])            # No stereo -> self-loop \n",
    "\n",
    "    if undirected: edge_index, edge_attr = to_undirected(edge_index, edge_attr)\n",
    "    if self_loops: edge_index, edge_attr = add_self_loops( edge_index, edge_attr, fill_value = self_loop_feature_vector)\n",
    "\n",
    "    return edge_index, edge_attr\n",
    "\n",
    "\n",
    "\n",
    "def atom_features(mol, padding_len): # padding: first append n zeros (length of amino acid embeddings)\n",
    "\n",
    "    x = []\n",
    "    rdPartialCharges.ComputeGasteigerCharges(mol)\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "\n",
    "        padding = [0 for n in range(padding_len)]\n",
    "        symbol = atom.GetSymbol()\n",
    "\n",
    "        if symbol in metals: \n",
    "            symbol = 'metal'\n",
    "        elif symbol in halogens:\n",
    "            symbol = 'halogen'\n",
    "\n",
    "        if symbol == 'H':\n",
    "            atom_encoding = [0 for i in range(len(all_atoms))]\n",
    "        else: \n",
    "            atom_encoding = one_of_k_encoding(symbol, all_atoms)\n",
    "        \n",
    "        ringm = [atom.IsInRing()]\n",
    "        hybr = atom.GetHybridization()\n",
    "        charge = [float(atom.GetFormalCharge())] \n",
    "        #charge = [float(atom.GetProp('_GasteigerCharge'))] \n",
    "        aromatic = [atom.GetIsAromatic()]\n",
    "        mass = [atom.GetMass()/100]\n",
    "        numHs = atom.GetTotalNumHs()\n",
    "        degree = atom.GetDegree()\n",
    "        chirality = str(atom.GetChiralTag())\n",
    "\n",
    "    \n",
    "        results =   padding + \\\n",
    "                    atom_encoding + \\\n",
    "                    ringm  + \\\n",
    "                    one_of_k_encoding(hybr, [Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2, Chem.rdchem.HybridizationType.SP2D, \n",
    "                                             Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2, Chem.rdchem.HybridizationType.UNSPECIFIED]) + \\\n",
    "                    charge + \\\n",
    "                    aromatic + \\\n",
    "                    mass + \\\n",
    "                    one_of_k_encoding(numHs, [0, 1, 2, 3, 4]) + \\\n",
    "                    one_of_k_encoding_unk(degree,[0, 1, 2, 3, 4, 5, 6, 7, 8, 'OTHER']) + \\\n",
    "                    one_of_k_encoding_unk(chirality, ['CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW', 'OTHER'])     \n",
    "        \n",
    "        x.append(results)  \n",
    "\n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "\n",
    "def edge_index_and_attr(mol, pos, undirected = True, self_loops = True):\n",
    "\n",
    "    edge_index = [[],[]]\n",
    "    edge_attr = []\n",
    "\n",
    "    #  Edge Attributes - Loop over edges and compute feature vector\n",
    "    #--------------------------------------------------------------------    \n",
    "    for bond in mol.GetBonds():\n",
    "\n",
    "        atm1 = bond.GetBeginAtomIdx()\n",
    "        atm2 = bond.GetEndAtomIdx()\n",
    "\n",
    "        edge_index[0].append(atm1)\n",
    "        edge_index[1].append(atm2)\n",
    "\n",
    "\n",
    "        # Generate Edge Feature Vector\n",
    "        #--------------------------------------------------------------------\n",
    "        edge_feature_vector = []\n",
    "        #print(f'Bond {bond.GetIdx()} between atoms {atm1, atm2}')\n",
    "\n",
    "        # Edge Type (covalent bond, non-covalent_bond, self-loop)\n",
    "        #print('---Covalent/Self-Loop/Non-Covalent: ', one_of_k_encoding_unk('covalent', ['covalent','self-loop','non-covalent']))\n",
    "        edge_feature_vector.extend(one_of_k_encoding('covalent', ['covalent','self-loop','non-covalent']))\n",
    "\n",
    "        # Length of Edge\n",
    "        length = np.linalg.norm(pos[atm1]-pos[atm2])\n",
    "        #print('---Bond Length: ', length )\n",
    "        edge_feature_vector.append(length/10)\n",
    "\n",
    "        # Bond Type (single, double, aromatic)\n",
    "        #print('---Bond Type: ', one_of_k_encoding_unk(bond.GetBondTypeAsDouble(), [1.0, 1.5, 2.0, 'non-covalent']))\n",
    "        edge_feature_vector.extend(one_of_k_encoding(bond.GetBondTypeAsDouble(), [0.,1.0,1.5,2.0,3.0]))\n",
    "\n",
    "        # Conjugated\n",
    "        #print('---Is Conjugated: ', [bond.GetIsConjugated()])\n",
    "        edge_feature_vector.append(bond.GetIsConjugated())\n",
    "\n",
    "        # Is in Ring?\n",
    "        #print('---Is in Ring: ', [bond.IsInRing()])\n",
    "        edge_feature_vector.append(bond.IsInRing())\n",
    "\n",
    "        # Stereo\n",
    "        allowed = [Chem.rdchem.BondStereo.STEREONONE,\n",
    "                Chem.rdchem.BondStereo.STEREOANY, \n",
    "                Chem.rdchem.BondStereo.STEREOE, \n",
    "                Chem.rdchem.BondStereo.STEREOZ, \n",
    "                Chem.rdchem.BondStereo.STEREOCIS, \n",
    "                Chem.rdchem.BondStereo.STEREOTRANS]\n",
    "        \n",
    "        #print('---Bond Stereo: ', one_of_k_encoding(bond.GetStereo(), allowed))\n",
    "        edge_feature_vector.extend(one_of_k_encoding(bond.GetStereo(), allowed))\n",
    "\n",
    "        edge_attr.append(edge_feature_vector)\n",
    "\n",
    "    # Make undirected and add self loops if necessary\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float64)\n",
    "    edge_index, edge_attr = make_undirected_with_self_loops(edge_index, edge_attr, undirected=undirected, self_loops=self_loops)\n",
    "    return edge_index, edge_attr\n",
    "\n",
    "\n",
    "\n",
    "all_atoms = ['B', 'C', 'N', 'O', 'P', 'S', 'Se', 'metal', 'halogen']\n",
    "halogens = ['F', 'Cl', 'Br', 'I', 'At'] #Halogen atoms Fluorine (F), Chlorine (Cl), Bromine (Br), Iodine (I), and Astatine (At)\n",
    "metals = [\n",
    "    # Alkali Metals\n",
    "    'Li', 'Na', 'K', 'Rb', 'Cs', 'Fr',\n",
    "    # Alkaline Earth Metals\n",
    "    'Be', 'Mg', 'Ca', 'Sr', 'Ba', 'Ra',\n",
    "    # Transition Metals\n",
    "    'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd',\n",
    "    'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
    "    'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn',\n",
    "    'Nh', 'Fl', 'Mc', 'Lv',\n",
    "    # Lanthanides\n",
    "    'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', \n",
    "    'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "    # Actinides\n",
    "    'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', \n",
    "    'Es', 'Fm', 'Md', 'No', 'Lr',\n",
    "    # Post-Transition Metals\n",
    "    'Al', 'Ga', 'In', 'Sn', 'Tl', 'Pb', 'Bi', 'Nh', 'Fl', 'Mc', 'Lv',\n",
    "    # Half-Metals\n",
    "    'As', 'Si', 'Sb', 'Te'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "amino_acids = [\"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLN\", \"GLU\", \"GLY\", \"HIS\", \"ILE\", \"LEU\",\n",
    "               \"LYS\", \"MET\", \"PHE\", \"PRO\", \"SER\", \"THR\", \"TRP\", \"TYR\", \"VAL\"]\n",
    "\n",
    "hetatm_smiles_dict1 = {'ZN': '[Zn+2]', 'MG': '[Mg+2]', 'NA': '[Na+1]', 'MN': '[Mn+2]', 'CA': '[Ca+2]', 'K': '[K+1]',\n",
    "                      'NI': '[Ni+2]', 'FE': '[Fe+2]', 'CO': '[Co+2]', 'HG': '[Hg+2]', 'CD': '[Cd+2]', 'CU': '[Cu+2]', \n",
    "                      'CS': '[Cs+1]', 'AU': '[Au+1]', 'LI': '[Li+1]', 'GA': '[Ga+3]', 'IN': '[In+3]', 'BA': '[Ba+2]',\n",
    "                      'RB': '[Rb+1]', 'SR': '[Sr+2]'}\n",
    "\n",
    "hetatm_smiles_dict2 = {'Zn': '[Zn+2]', 'Mg': '[Mg+2]', 'Na': '[Na+1]', 'Mn': '[Mn+2]', 'Ca': '[Ca+2]', 'K': '[K+1]',\n",
    "                      'Ni': '[Ni+2]', 'Fe': '[Fe+2]', 'Co': '[Co+2]', 'Hg': '[Hg+2]', 'Cd': '[Cd+2]', 'Cu': '[Cu+2]', \n",
    "                      'Cs': '[Cs+1]', 'Au': '[Au+1]', 'Li': '[Li+1]', 'Ga': '[Ga+3]', 'In': '[In+3]', 'Ba': '[Ba+2]',\n",
    "                      'Rb': '[Rb+1]', 'Sr': '[Sr+2]'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Protein PDBs: 16\n",
      "Number of Ligand SDFs: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file into a dictionary\n",
    "with open(affinity_dict_path, 'r', encoding='utf-8') as json_file:\n",
    "    affinity_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "# Get sorted lists of proteins and ligands (dirEntry objects) in the data_dir\n",
    "proteins = sorted([protein for protein in os.scandir(data_dir) if protein.name.endswith('protein.pdb')], key=lambda x: x.name)\n",
    "ligands = sorted([ligand for ligand in os.scandir(data_dir) if ligand.name.endswith('ligand.sdf')], key=lambda x: x.name)\n",
    "\n",
    "if not len(proteins) == len(ligands):\n",
    "    raise ValueError('Number of proteins and ligands does not match')\n",
    "else:\n",
    "    print(f'Number of Protein PDBs: {len(proteins)}')\n",
    "    print(f'Number of Ligand SDFs: {len(ligands)}')\n",
    "\n",
    "\n",
    "# Initialize Log File:\n",
    "log_folder = os.path.join(data_dir,'.logs/')\n",
    "if not os.path.exists(log_folder): os.makedirs(log_folder)\n",
    "log_file_path = os.path.join(log_folder, \"preprocessing_logs.txt\")\n",
    "log = open(log_file_path, 'a')\n",
    "log.write(\"Data Preprocessing - Log File:\\n\")\n",
    "log.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:32:58] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 35,  88,  90,  94, 245, 307, 309, 310]), array([ 35,  45,  88,  90,  94, 307, 310]), array([ 35,  45,  48,  88,  90,  94, 310]), array([ 33,  35,  45,  48,  88,  90, 310]), array([33, 35, 45, 48, 88, 90]), array([ 35,  88,  94,  96, 307, 315]), array([ 35,  88,  94,  96, 247, 307, 315]), array([ 35,  88,  94,  96, 245, 247, 257, 307, 315]), array([ 88,  94,  96, 245, 247, 257, 307, 315]), array([ 88,  94,  96, 245, 257, 307]), array([ 35,  88,  94, 245, 257, 307, 309, 310]), array([ 90,  94, 310, 311]), array([ 90,  94, 311]), array([ 94, 310, 311]), array([ 90, 311]), array([ 35,  94, 245, 307, 308, 309, 310]), array([ 94, 243, 245, 307, 309, 310]), array([ 35,  88,  90,  94, 245, 307, 309, 310]), array([ 90,  94, 310, 311]), array([31, 90]), array([ 90, 311]), array([ 94, 309, 310, 311]), array([ 35,  88,  94, 245, 307, 309, 310])]\n",
      "[31, 33, 35, 45, 48, 88, 90, 94, 96, 243, 245, 247, 257, 307, 308, 309, 310, 311, 315]\n",
      "['TYR', 'GLY', 'TYR', 'LEU', 'HIS', 'LEU', 'TYR', 'ARG', 'PHE', 'VAL', 'HIS', 'VAL', 'TRP', 'LYS', 'ARG', 'GLY', 'TYR', 'TYR', 'TRP']\n",
      "Numpy Time: 0.03157448768615723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:32:58] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 10,  48,  50,  91, 129]), array([  8,  10,  40,  48,  50, 129]), array([  8,  10,  40,  48, 129]), array([  8,  10,  40,  48, 129]), array([  8,  10,  40,  48,  50, 129]), array([ 8, 48, 50]), array([ 10,  48,  50,  91, 129]), array([ 10,  40,  48, 129]), array([  8,  10,  40,  44,  48, 129]), array([  8,  10,  40, 124, 126, 129]), array([ 8, 10, 48, 50, 91]), array([  8,  50, 124]), array([48, 91]), array([ 48,  50,  91, 131]), array([ 91, 131, 134]), array([ 50,  91, 118, 131, 134]), array([ 50,  70,  91, 118, 134]), array([ 50,  70,  91, 118, 134]), array([ 91, 131, 134, 906]), array([ 48,  50,  91, 118, 134]), array([ 91, 129, 130, 131]), array([118, 122, 124, 131, 134]), array([ 50,  70, 118, 134])]\n",
      "[8, 10, 40, 44, 48, 50, 70, 91, 118, 122, 124, 126, 129, 130, 131, 134, 906]\n",
      "['TYR', 'ARG', 'ARG', 'GLN', 'TYR', 'GLU', 'MET', 'ARG', 'PHE', 'ASN', 'ASP', 'HIS', 'ASP', 'SER', 'ASP', 'PHE', 'ASP']\n",
      "Numpy Time: 0.049070119857788086\n",
      "[array([118, 164]), array([118, 164]), array([118]), array([118, 164]), array([118, 164, 165, 166]), array([118, 164, 165]), array([164]), array([118, 164, 165, 166]), array([118, 164, 165, 166]), array([118, 140, 142, 164, 166]), array([118, 148, 164, 165, 166]), array([118, 140, 142, 166]), array([118, 138, 140, 148, 164, 165, 166]), array([118, 138, 140, 142, 148, 164, 166]), array([118, 138, 140, 141, 142, 143, 148, 164, 166]), array([118, 138, 140, 141, 142, 148]), array([118, 138, 140, 141, 142, 143]), array([118, 138, 139, 140, 141, 142, 143, 148]), array([118, 138, 140, 141, 142, 148, 164]), array([164, 165, 166]), array([164, 165]), array([164, 165]), array([164, 165, 166]), array([163, 164, 165]), array([163, 164, 165]), array([163, 164, 165]), array([163, 165]), array([163, 164]), array([165]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([165, 178]), array([165, 177, 178]), array([165, 177, 178, 199, 200]), array([165, 177, 178, 198, 199, 200])]\n",
      "[118, 138, 139, 140, 141, 142, 143, 148, 163, 164, 165, 166, 177, 178, 198, 199, 200]\n",
      "['ARG', 'ARG', 'GLU', 'SER', 'GLU', 'THR', 'THR', 'CYS', 'LYS', 'HIS', 'TYR', 'LYS', 'ILE', 'THR', 'ASP', 'GLY', 'LEU']\n",
      "Numpy Time: 0.01105809211730957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:32:59] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:32:59] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([118, 164]), array([118, 164]), array([118]), array([118, 164]), array([118, 164, 165, 166]), array([118, 164, 165]), array([164]), array([118, 164, 165, 166]), array([118, 164, 165, 166]), array([118, 140, 142, 166]), array([118, 138, 140, 148, 164, 165, 166]), array([118, 140, 142, 166]), array([118, 138, 140, 148, 164, 165, 166]), array([118, 138, 140, 142, 148, 164, 166]), array([118, 138, 140, 141, 142, 143, 148, 164, 166]), array([118, 138, 140, 141, 142, 148]), array([118, 138, 140, 141, 142]), array([118, 138, 139, 140, 141, 142, 143, 148]), array([118, 138, 140, 141, 142, 148, 164]), array([164, 165, 166]), array([164, 165]), array([165]), array([164, 165, 166]), array([163, 164, 165]), array([163, 164, 165]), array([163, 164, 165]), array([163, 165]), array([163, 164]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([165, 177, 178]), array([165, 177, 178]), array([165, 177, 178, 199, 200]), array([165, 178, 199]), array([165, 178, 199, 200]), array([165, 177, 178, 198, 199, 200])]\n",
      "[118, 138, 139, 140, 141, 142, 143, 148, 163, 164, 165, 166, 177, 178, 198, 199, 200]\n",
      "['ARG', 'ARG', 'GLU', 'SER', 'GLU', 'THR', 'THR', 'CYS', 'LYS', 'HIS', 'TYR', 'LYS', 'ILE', 'THR', 'ASP', 'GLY', 'LEU']\n",
      "Numpy Time: 0.009271383285522461\n",
      "[array([117, 163]), array([117, 163]), array([117]), array([117, 163]), array([117, 163, 164, 165]), array([117, 163, 164]), array([163]), array([117, 163, 164, 165]), array([117, 163, 164, 165]), array([117, 139, 141, 165]), array([117, 137, 139, 147, 163, 164, 165]), array([117, 139, 141, 165]), array([117, 137, 139, 147, 163, 164, 165]), array([117, 137, 139, 141, 147, 163, 165]), array([117, 137, 139, 140, 141, 142, 147, 163, 165]), array([117, 137, 139, 140, 141, 147]), array([117, 137, 139, 140, 141]), array([117, 137, 138, 139, 140, 141, 147]), array([117, 137, 139, 140, 141, 147, 163]), array([163, 164, 165]), array([163, 164]), array([163, 164]), array([163, 164, 165]), array([162, 163, 164]), array([162, 163, 164]), array([162, 163, 164]), array([162, 164]), array([162, 163]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([164]), array([], dtype=int64), array([], dtype=int64), array([164, 177]), array([164, 177, 198]), array([164, 176, 177, 198, 199]), array([164, 176, 177, 198, 199])]\n",
      "[117, 137, 138, 139, 140, 141, 142, 147, 162, 163, 164, 165, 176, 177, 198, 199]\n",
      "['ARG', 'ARG', 'GLU', 'SER', 'GLU', 'THR', 'THR', 'CYS', 'LYS', 'HIS', 'TYR', 'LYS', 'ILE', 'THR', 'GLY', 'LEU']\n",
      "Numpy Time: 0.008896350860595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:32:59] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:32:59] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([257, 259]), array([182, 257, 258, 259, 260, 262]), array([258, 262, 265]), array([257, 258, 259]), array([257, 258, 259, 262]), array([182, 257, 258, 259, 262]), array([258, 259, 262]), array([182, 258, 259, 262]), array([258, 259, 262]), array([258, 259, 262]), array([258, 259, 262]), array([258, 259, 262]), array([256, 257, 258, 259]), array([256, 257, 258, 259]), array([256, 257]), array([255, 256, 257]), array([256, 257, 258]), array([208, 256, 257, 258]), array([208, 256, 257, 258]), array([208, 256, 257, 258, 259]), array([ 86, 231, 234, 256, 257]), array([83, 86]), array([132, 256, 257]), array([ 79, 231, 234, 255, 256, 257]), array([ 79, 132, 234, 255, 256, 257]), array([ 79, 132, 234, 255, 256]), array([ 83, 132, 256]), array([ 79,  83, 132]), array([ 79,  83,  86, 132]), array([83, 86]), array([86]), array([132, 256, 257]), array([ 79,  80, 231, 232, 234, 255]), array([ 79, 231, 234, 255, 256, 257]), array([228, 229, 230, 231, 256, 257, 259, 260, 267, 268]), array([228, 229, 230, 256, 257, 258, 259, 260, 261, 266, 267, 268]), array([228, 229, 230, 254, 256, 257, 260, 267, 268, 269]), array([ 79, 230, 231, 232, 234, 254, 255, 256]), array([ 79, 229, 230, 231, 232, 233, 234, 254, 255, 256]), array([229, 230, 231, 234, 254, 255, 256, 257]), array([229, 230, 231, 254, 255, 256, 257, 267, 268]), array([228, 229, 230, 256, 257, 259, 260, 261, 267, 268]), array([ 79, 230, 231, 232, 233, 234, 254, 255]), array([228, 229, 230, 254, 256, 257, 267, 268, 269])]\n",
      "[79, 80, 83, 86, 132, 182, 208, 228, 229, 230, 231, 232, 233, 234, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 269]\n",
      "['HIS', 'CYS', 'TYR', 'TRP', 'LEU', 'GLU', 'ILE', 'ASP', 'ALA', 'CYS', 'GLU', 'GLY', 'ASP', 'SER', 'VAL', 'SER', 'TRP', 'GLY', 'GLU', 'GLY', 'CYS', 'ASP', 'ARG', 'LYS', 'TYR', 'GLY', 'PHE', 'TYR']\n",
      "Numpy Time: 0.01571488380432129\n",
      "[array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([96]), array([96]), array([96]), array([95, 96]), array([], dtype=int64), array([51]), array([], dtype=int64), array([96]), array([46, 51, 96]), array([51, 96]), array([51]), array([46, 51, 52, 89, 96]), array([46, 51, 52, 53, 89, 95, 96]), array([46, 51, 52, 53, 95, 96]), array([46, 52, 53, 89, 95, 96]), array([46, 51, 52, 53, 95, 96]), array([44, 46, 52, 53, 89, 95, 96]), array([44, 46, 52, 53, 95, 96]), array([96, 97]), array([96, 97, 98]), array([51, 96, 98]), array([46, 51, 89, 96, 98]), array([96, 97, 98]), array([96, 97, 98]), array([97, 98]), array([96, 97, 98]), array([97, 98]), array([51, 98]), array([51, 98]), array([51, 98]), array([51, 98]), array([51]), array([51]), array([51]), array([51]), array([51]), array([51, 98]), array([ 51,  98, 105]), array([], dtype=int64), array([], dtype=int64), array([ 51, 105]), array([ 46,  51,  87,  89,  98, 105]), array([ 87,  98, 105]), array([ 46,  51,  89,  98, 105]), array([105]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([98]), array([ 98, 105]), array([ 98, 105]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([107]), array([107]), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([107]), array([ 87, 107]), array([ 48,  87, 107]), array([ 48,  87, 107]), array([ 87, 105, 107]), array([ 87, 105, 107]), array([ 87, 105, 107]), array([ 87, 105]), array([105]), array([ 98, 105]), array([ 98, 105]), array([ 98, 105]), array([48, 87]), array([48, 87]), array([], dtype=int64), array([], dtype=int64), array([48, 51, 87]), array([], dtype=int64)]\n",
      "[44, 46, 48, 51, 52, 53, 87, 89, 95, 96, 97, 98, 105, 107]\n",
      "['MET', 'PHE', 'LYS', 'GLN', 'GLU', 'LEU', 'LEU', 'ARG', 'ARG', 'THR', 'ARG', 'TYR', 'ILE', 'MET']\n",
      "Numpy Time: 0.03353738784790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:00] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:33:00] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 40,  73, 216, 298, 332, 333]), array([ 40, 216, 271, 272, 298, 333]), array([ 40,  41,  73, 216, 298, 332, 333]), array([ 40,  41,  73, 200, 216, 298, 333]), array([ 40,  41,  73, 200, 216, 298, 333]), array([ 40,  41,  73, 150, 200, 333]), array([ 73,  74, 200, 333]), array([ 73,  74, 145, 147, 150, 200]), array([ 73,  74, 101, 102, 145, 147]), array([ 73,  74, 101, 145, 147]), array([ 73,  74, 101, 102, 145, 147, 150]), array([ 73, 147, 200, 216, 333]), array([ 40,  73, 200, 216, 298, 333]), array([147, 169, 199, 200, 216, 333]), array([ 73,  74, 147, 169, 216]), array([147, 169, 199, 200, 216, 218, 333]), array([147, 199, 200, 216, 218, 333]), array([147, 169, 199, 216, 218]), array([147, 169, 197, 199, 218]), array([ 41,  73,  74,  78, 101, 333]), array([ 41,  73,  74,  78, 101, 102, 150]), array([ 41,  73,  78, 101, 102, 150, 333]), array([ 41,  56,  73,  74,  78, 101, 102]), array([ 41,  72,  73,  74,  78, 101])]\n",
      "[40, 41, 56, 72, 73, 74, 78, 101, 102, 145, 147, 150, 169, 197, 199, 200, 216, 218, 271, 272, 298, 332, 333]\n",
      "['ARG', 'GLU', 'LEU', 'GLU', 'ASP', 'ARG', 'ARG', 'TRP', 'SER', 'ILE', 'ARG', 'GLU', 'ALA', 'HIS', 'GLU', 'GLU', 'ARG', 'ASN', 'GLY', 'ILE', 'ARG', 'TRP', 'TYR']\n",
      "Numpy Time: 0.05838894844055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:01] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:33:01] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 37,  98, 121, 122, 123, 124, 125]), array([ 37,  84,  93, 124, 136, 171, 173]), array([ 37,  38,  41,  84, 171, 173]), array([ 37,  38,  41,  79,  82,  83,  84, 171]), array([40, 44, 82]), array([84, 88, 92]), array([40, 44]), array([36, 37, 40, 44]), array([ 98, 121]), array([ 37,  98, 121, 122, 123, 124]), array([ 37,  38,  41,  79,  84, 171, 173]), array([ 37,  98, 121, 122, 123, 124, 125]), array([ 92,  93,  98, 121, 122, 124, 125]), array([ 37,  93, 124]), array([ 84,  92,  93, 124]), array([ 84,  93, 124]), array([ 37,  84,  93, 124, 173]), array([ 37,  41,  84, 171, 173]), array([37, 40, 41, 84]), array([37, 40, 41, 44, 82, 84]), array([40, 41, 44, 82, 84]), array([44, 82, 84]), array([44, 84, 92]), array([44, 92]), array([44, 92, 98]), array([44, 98]), array([40, 44, 98]), array([40, 44]), array([37, 40]), array([37, 40]), array([ 37,  98, 121, 123, 124]), array([ 98, 121]), array([ 92,  93,  98, 121, 122, 124, 125]), array([ 84,  93, 124, 136, 171, 173]), array([ 37,  38,  41,  79,  84, 171, 173]), array([37, 40, 41]), array([40, 41, 44, 82, 83, 84]), array([84, 88, 92]), array([92, 98]), array([40, 44])]\n",
      "[36, 37, 38, 40, 41, 44, 79, 82, 83, 84, 88, 92, 93, 98, 121, 122, 123, 124, 125, 136, 171, 173]\n",
      "['SER', 'ASN', 'ALA', 'ASP', 'ALA', 'LYS', 'ASP', 'ILE', 'GLY', 'MET', 'GLU', 'ASN', 'LEU', 'LYS', 'GLY', 'VAL', 'GLY', 'PHE', 'TYR', 'VAL', 'THR', 'LEU']\n",
      "Numpy Time: 0.02073502540588379\n",
      "[array([681, 682, 750, 751, 752]), array([680, 681, 682, 750, 751]), array([680, 681, 682, 751]), array([680, 681, 682, 750, 751]), array([681, 682, 683, 749, 750, 751]), array([681, 682, 683, 749, 750, 751]), array([682, 683, 700, 749, 750, 751]), array([683, 700, 749, 750, 751]), array([683, 700, 751]), array([683, 700, 751]), array([683, 685, 700, 749, 751]), array([683, 685, 700, 749, 751]), array([683, 685, 697, 700, 749]), array([685, 700]), array([683, 700, 751]), array([683, 684, 685, 700, 749, 751]), array([700, 751]), array([530, 535, 685, 697, 700, 749, 754, 756]), array([530, 535, 685, 749, 750, 751, 754, 755]), array([530, 749, 751, 754]), array([530, 535, 697, 700, 754]), array([530, 535, 685, 697, 700, 756]), array([530, 700, 754]), array([530, 700, 754]), array([700, 754]), array([533, 700]), array([754]), array([754]), array([754]), array([], dtype=int64), array([754])]\n",
      "[530, 533, 535, 680, 681, 682, 683, 684, 685, 697, 700, 749, 750, 751, 752, 754, 755, 756]\n",
      "['VAL', 'VAL', 'PRO', 'THR', 'ASN', 'TYR', 'GLY', 'MET', 'ASN', 'TRP', 'TRP', 'ALA', 'GLU', 'ARG', 'LEU', 'ARG', 'THR', 'PHE']\n",
      "Numpy Time: 0.04509568214416504\n",
      "[array([ 55,  58,  59, 180, 181, 211, 214, 235, 292, 350]), array([ 14,  55,  58,  59, 180, 181, 211, 214, 350]), array([ 14,  55,  58,  59, 152, 180, 181, 211, 214, 350]), array([ 14,  55,  58,  59, 180, 181, 211, 293, 350]), array([ 14,  55,  58,  59, 180, 181, 211, 292, 293, 350]), array([ 14,  55,  58,  59, 181, 211, 214, 235, 266, 292, 293, 350]), array([ 12,  14,  55,  58, 211, 214, 235, 262, 292, 293, 350]), array([ 14,  58,  59,  62, 211, 292, 293, 350]), array([ 14,  58,  59,  62, 180, 181, 292, 293, 350]), array([ 14,  58,  59,  62, 152, 180, 181, 211, 293, 350]), array([ 14,  58,  59,  62, 152, 180, 181]), array([ 14,  16,  58,  59,  62, 152, 180, 181]), array([ 59,  62, 103, 152, 181]), array([ 14,  16,  59,  62, 103, 152]), array([ 16,  62,  66, 100, 103, 114, 152]), array([ 14,  16,  99, 100, 103, 150, 152, 180, 181]), array([ 14, 150, 152, 180, 181]), array([ 14,  16,  98,  99, 100, 103, 150, 152, 180]), array([ 14,  15,  16,  62,  98,  99, 100, 103, 150, 180])]\n",
      "[12, 14, 15, 16, 55, 58, 59, 62, 66, 98, 99, 100, 103, 114, 150, 152, 180, 181, 211, 214, 235, 262, 266, 292, 293, 350]\n",
      "['HIS', 'HIS', 'LEU', 'ASP', 'LEU', 'PHE', 'LEU', 'PHE', 'MET', 'ARG', 'TYR', 'SER', 'LEU', 'TRP', 'CYS', 'MET', 'ALA', 'GLY', 'HIS', 'GLU', 'HIS', 'SER', 'THR', 'ASP', 'ASP', 'ZN']\n",
      "Numpy Time: 0.029288291931152344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:01] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:33:02] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 40,  73, 216, 298, 332, 333]), array([ 40, 216, 271, 272, 298, 333]), array([ 40, 216, 298, 332, 333]), array([ 40,  41,  73, 200, 216, 298, 333]), array([ 40,  41,  73, 200, 216, 298, 333]), array([ 40,  41,  73,  78, 150, 200, 333]), array([ 41,  73,  74, 200, 333]), array([ 73,  74, 147, 150, 200]), array([ 73,  74, 101, 102, 145, 147]), array([ 73,  74, 101, 145]), array([ 73,  74, 101, 102, 145, 147, 150]), array([ 73, 200, 216, 333]), array([ 40,  73, 200, 216, 298, 333]), array([ 74, 147, 200, 216, 333]), array([ 73,  74, 216]), array([147, 169, 199, 200]), array([145, 147, 169, 199]), array([ 74, 145, 147, 169]), array([ 74, 145, 147, 169]), array([ 74, 145, 169]), array([144, 145, 147, 167, 168, 169]), array([144, 145, 168, 169]), array([144, 145, 147, 167, 168, 169, 170]), array([144, 145, 167, 168, 169, 170]), array([147, 169, 199, 200, 216, 333]), array([147, 169, 199, 200, 216, 218, 333]), array([147, 169, 199, 200, 216, 218]), array([40, 41, 73, 78])]\n",
      "[40, 41, 73, 74, 78, 101, 102, 144, 145, 147, 150, 167, 168, 169, 170, 199, 200, 216, 218, 271, 272, 298, 332, 333]\n",
      "['ARG', 'GLU', 'ASP', 'ARG', 'ARG', 'TRP', 'SER', 'ASN', 'ILE', 'ARG', 'GLU', 'GLY', 'SER', 'ALA', 'SER', 'GLU', 'GLU', 'ARG', 'ASN', 'GLY', 'ILE', 'ARG', 'TRP', 'TYR']\n",
      "Numpy Time: 0.05380582809448242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:02] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([202, 203, 204, 205, 206, 207]), array([202, 203, 204, 205, 206, 207]), array([202, 203, 205, 206, 207, 208, 247]), array([201, 202, 203, 204, 205, 206, 207]), array([203, 204, 205, 206, 207, 208]), array([203, 205, 206, 207, 208, 223]), array([203, 205, 207, 208, 223, 225]), array([205, 206, 207, 208, 209, 223]), array([203, 204, 205, 206, 207, 208, 223, 306]), array([203, 204, 205, 208, 306]), array([203, 205, 208, 306]), array([203, 205, 218, 306]), array([208, 218, 223]), array([223]), array([205, 208, 218, 223]), array([208, 218, 219, 223]), array([205, 208, 218, 306]), array([205, 208, 218, 306, 349]), array([204, 205, 208, 218, 306, 349]), array([204, 205, 208, 209, 218, 305, 306, 349, 350]), array([205, 208, 218, 306, 309, 348, 349, 350]), array([205, 218, 305, 306, 308, 309, 348, 349, 350]), array([218, 305, 306, 307, 308, 347, 348, 349, 350, 351]), array([218, 306, 308, 309, 348, 349, 350]), array([218, 306, 308, 309, 348, 350]), array([306, 308, 309, 348, 350]), array([218, 306, 308, 309, 350]), array([205, 208, 218, 306, 309, 349, 350])]\n",
      "[201, 202, 203, 204, 205, 206, 207, 208, 209, 218, 219, 223, 225, 247, 305, 306, 307, 308, 309, 347, 348, 349, 350, 351]\n",
      "['ASP', 'VAL', 'ALA', 'VAL', 'GLY', 'LYS', 'THR', 'CYS', 'LEU', 'PHE', 'PRO', 'VAL', 'THR', 'ASP', 'THR', 'GLN', 'ILE', 'ASP', 'LEU', 'CYS', 'SER', 'ALA', 'LEU', 'THR']\n",
      "Numpy Time: 0.031502485275268555\n",
      "[array([ 76, 246, 247]), array([73, 76]), array([73, 76]), array([73]), array([ 73, 122, 245]), array([ 73, 122, 197, 245]), array([122, 197, 245, 246, 247]), array([197, 245, 246, 247]), array([197, 245, 246, 247, 248]), array([245, 246, 247]), array([ 73, 120, 121, 122, 197, 245]), array([ 73, 120, 121, 122, 245]), array([ 73, 120, 121, 122, 197]), array([246, 247, 248]), array([ 76, 246, 248]), array([246, 247, 248, 251]), array([245, 246, 247, 248]), array([ 76, 245, 246, 248]), array([245, 246]), array([244, 245, 246]), array([220, 245, 246, 248]), array([219, 220, 245, 246, 248, 249]), array([218, 219, 220, 245, 246, 248, 249]), array([217, 218, 219, 220, 245, 246, 248, 249]), array([217, 218, 219, 243, 245, 246, 248, 249, 256, 257]), array([217, 218, 219, 223, 243, 244, 245, 246, 256, 257]), array([217, 218, 219, 243, 245, 246, 248, 249, 250, 256, 257]), array([ 69, 122, 244, 245, 246]), array([69, 76]), array([69, 73, 76, 78]), array([ 69,  73,  76,  78, 122]), array([ 69,  73, 122, 245]), array([ 69, 122, 223, 244, 245, 246]), array([ 69,  76, 220, 223]), array([ 69,  76,  78, 220, 221, 223]), array([ 76,  78, 220]), array([ 69,  70,  76,  78, 223]), array([76, 78]), array([ 76,  78, 220]), array([ 69,  76,  78, 220, 221, 223]), array([76, 78]), array([76, 78]), array([217, 218, 219, 246, 248, 249, 250, 256, 257])]\n",
      "[69, 70, 73, 76, 78, 120, 121, 122, 197, 217, 218, 219, 220, 221, 223, 243, 244, 245, 246, 247, 248, 249, 250, 251, 256, 257]\n",
      "['HIS', 'CYS', 'TYR', 'TRP', 'LYS', 'GLU', 'ASN', 'LEU', 'ILE', 'ASP', 'ALA', 'CYS', 'GLU', 'GLY', 'SER', 'VAL', 'SER', 'TRP', 'GLY', 'GLU', 'GLY', 'CYS', 'ASP', 'ARG', 'GLY', 'PHE']\n",
      "Numpy Time: 0.013456106185913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:02] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "[17:33:02] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 70,  77, 123, 224, 245, 246, 247]), array([ 70,  74,  77, 123, 224, 245, 246]), array([ 70,  74,  77, 123]), array([ 74,  77, 123]), array([ 77, 247]), array([ 77, 246, 247, 248]), array([ 77, 123, 246, 247]), array([ 74,  77, 123]), array([ 77, 123, 245, 246, 247]), array([123, 221, 245, 246, 247]), array([ 70,  77, 123, 221, 224, 245, 246, 247]), array([ 77, 221, 224, 246, 247]), array([221, 246, 247, 248, 249]), array([198, 246, 247, 248]), array([123, 198, 246, 247, 248]), array([ 74, 198]), array([ 74, 121, 122, 123, 198]), array([ 74, 121, 122, 123, 198]), array([ 74, 121, 122, 123, 198, 246]), array([122, 123, 198, 246, 247]), array([ 70,  77, 221, 224, 245, 246, 247]), array([ 70, 220, 221, 222, 224, 244, 245, 246]), array([ 70, 220, 221, 222, 223, 224, 244, 245]), array([220, 221, 222, 223, 224, 244]), array([ 70, 220, 221, 222, 223, 224, 244, 245, 246, 247]), array([219, 220, 221, 224, 244, 245, 246, 247]), array([219, 220, 221, 223, 244, 246, 247]), array([218, 219, 220, 221, 246, 247, 248, 249, 250, 257]), array([218, 219, 220, 246, 247, 248, 249, 250, 257, 258]), array([218, 219, 220, 244, 246, 247, 249, 250, 257, 258, 259]), array([218, 219, 220, 247, 248, 249, 250, 251, 257]), array([ 54,  79, 221, 222, 224]), array([ 53,  54,  55, 222]), array([ 53,  54,  55, 221, 222]), array([ 53, 169, 170, 221, 222]), array([170, 221, 222]), array([ 54, 221, 222]), array([ 54,  55,  77,  79, 222, 224]), array([ 77,  79, 221, 222, 224]), array([ 77,  79, 221, 222, 224]), array([ 70,  77,  79, 221, 222, 224]), array([ 55,  70,  71,  77,  79, 221, 222, 224]), array([218, 219, 220, 247, 248, 249, 250, 251, 257])]\n",
      "[53, 54, 55, 70, 71, 74, 77, 79, 121, 122, 123, 169, 170, 198, 218, 219, 220, 221, 222, 223, 224, 244, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259]\n",
      "['LEU', 'LEU', 'CYS', 'HIS', 'CYS', 'TYR', 'TRP', 'LYS', 'GLU', 'ASN', 'LEU', 'GLY', 'ASN', 'ILE', 'ASP', 'ALA', 'CYS', 'GLU', 'GLY', 'ASP', 'SER', 'VAL', 'SER', 'TRP', 'GLY', 'GLU', 'GLY', 'CYS', 'ASP', 'GLY', 'PHE', 'TYR']\n",
      "Numpy Time: 0.013948440551757812\n",
      "[array([ 47, 199, 200, 201, 203, 221, 222, 223, 224]), array([199, 200, 201, 203, 221, 222, 223, 224]), array([199, 200, 223, 224, 226, 227]), array([198, 199, 200, 223, 224, 225, 226, 227]), array([198, 199, 200, 202, 203, 221, 222, 223, 224]), array([198, 199, 202, 221, 223, 224]), array([197, 198, 199, 221, 223, 224, 226, 227, 234]), array([197, 198, 199, 223, 224, 225, 226, 227, 234, 235]), array([197, 198, 199, 221, 223, 224, 226, 227, 234, 235, 236]), array([197, 198, 199, 224, 225, 226, 227, 228, 234]), array([ 93, 223, 224]), array([ 93, 223, 224, 225]), array([223, 224, 225]), array([174, 223, 224, 225]), array([ 93, 223, 224]), array([ 91,  93, 223, 224]), array([ 91,  92,  93, 174, 223, 224, 225]), array([ 91,  92,  93, 174, 175, 223]), array([ 91,  92,  93, 174, 175, 180, 223]), array([ 91,  92, 174, 175, 223]), array([ 47,  93, 200, 201, 203, 222, 223, 224]), array([200, 201, 203]), array([ 93, 200, 203]), array([ 47,  93, 200, 203]), array([ 47,  93, 203, 223]), array([ 93, 200, 223, 224]), array([ 93, 200, 203, 222, 223, 224]), array([ 93, 200, 222, 223, 224]), array([197, 198, 199, 224, 225, 226, 227, 228, 229, 234]), array([ 91,  92,  93, 174, 175, 180, 223])]\n",
      "[47, 91, 92, 93, 174, 175, 180, 197, 198, 199, 200, 201, 202, 203, 221, 222, 223, 224, 225, 226, 227, 228, 229, 234, 235, 236]\n",
      "['HIS', 'ASP', 'THR', 'TYR', 'ARG', 'THR', 'MET', 'ASP', 'ALA', 'CYS', 'GLN', 'GLY', 'ASP', 'SER', 'ILE', 'SER', 'TRP', 'GLY', 'LEU', 'GLY', 'CYS', 'GLY', 'GLN', 'GLY', 'VAL', 'TYR']\n",
      "Numpy Time: 0.016391277313232422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:03] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n"
     ]
    }
   ],
   "source": [
    "# Initialize PDB Parser\n",
    "parser = PDBParser(PERMISSIVE=1, QUIET=True)\n",
    "\n",
    "amino_acids = [\"ALA\",\"ARG\",\"ASN\",\"ASP\",\"CYS\",\"GLN\",\"GLU\",\"GLY\",\"HIS\",\"ILE\",\"LEU\",\"LYS\",\"MET\",\"PHE\",\"PRO\",\"SER\",\"THR\",\"TRP\",\"TYR\",\"VAL\"]\n",
    "known_hetatms = ['ZN','MG','NA','MN','CA','K','NI','FE','CO','HG','CD','CU','CS','AU','LI','GA','IN','BA','RB','SR']\n",
    "known_residues = amino_acids + known_hetatms\n",
    "\n",
    "\n",
    "# Here start a loop over the complexes\n",
    "#----------------------------------------------------------\n",
    "for protein, ligand in zip(proteins, ligands):\n",
    "    \n",
    "    if protein.name.split('_')[0] != ligand.name.split('_')[0]:\n",
    "        raise ValueError(f'Protein {protein} and Ligand {ligand} do not match')\n",
    "    else:\n",
    "        protein_id = protein.name.split('_')[0]\n",
    "        protein_path = protein.path\n",
    "        ligand_path = ligand.path\n",
    "    \n",
    "    log_string = f'{protein_id}: '\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # PRESELECTION OF COMPLEXES\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    # TEST 1: AFFINITY DATA - Continue only if there is a valid affinity value available for this complex\n",
    "    if protein_id not in affinity_dict.keys():\n",
    "        log_string += 'Protein is not processed: No valid affinity value'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "\n",
    "    # TEST 2: LIGAND PARSING - Continue only if the parsed ligand has been processed successfully, else skip this complex\n",
    "    ligand = parse_sdf_file(ligand_path)\n",
    "    if len(ligand) == 1: mol = ligand[0]\n",
    "    else:\n",
    "        log_string += 'Ligand could not be parsed successfully'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "    \n",
    "    # TEST 3: LIGAND SIZE - Get coordinate Matrix of the ligand molecule - Continue only if the ligand has at least 5 heavy atoms\n",
    "    conformer = mol.GetConformer()\n",
    "    coordinates = conformer.GetPositions()\n",
    "    pos = np.array(coordinates)\n",
    "    if pos.shape[0]<5:\n",
    "        log_string += 'Ligand is smaller than 5 Atoms and is skipped'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # PARSING OF PROTEIN PDB TO GENERATE COORDINATE MATRIX\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    with open(protein_path) as pdbfile:\n",
    "        protein = parse_pdb(parser, protein_id, pdbfile)\n",
    "\n",
    "\n",
    "    protein_atomcoords = np.array([], dtype=np.int64).reshape(0,3)\n",
    "    res_list = []\n",
    "    residue_memberships = []\n",
    "        \n",
    "    clean_aa_chain = False\n",
    "    chain_too_long = False\n",
    "    residue_idx = 1\n",
    "\n",
    "    # Iterate over the chains in the protein\n",
    "    for chain in protein:\n",
    "\n",
    "        chain_comp = protein[chain]['composition']\n",
    "\n",
    "        # CHAIN CONTAINS ONLY AMINO ACIDS (AND HETATMS in chain)\n",
    "        if chain_comp == [True, False] or chain_comp == [True, True]:\n",
    "            clean_aa_chain = True\n",
    "\n",
    "            # If the chain is longer than 1024, skip the complex\n",
    "            if len(protein[chain]['aa_seq']) > 1022:\n",
    "                chain_too_long = True\n",
    "                break\n",
    "            \n",
    "            for residue in protein[chain]['aa_residues']:\n",
    "                res_dict = protein[chain]['aa_residues'][residue]\n",
    "\n",
    "                # Append the coords of the residue to the protein_atomcoords\n",
    "                protein_atomcoords = np.vstack((protein_atomcoords, res_dict['coords']))\n",
    "\n",
    "                res_list.append((residue_idx, res_dict['resname']))\n",
    "                \n",
    "                memb = [residue_idx for atom in res_dict['atom_indeces']]\n",
    "                residue_memberships.extend(memb)\n",
    "\n",
    "                residue_idx += 1\n",
    "        \n",
    "        # CHAIN CONTAINS HETATMS BUT NO AMINO ACIDS\n",
    "        elif protein[chain]['composition'] == [False, True]: \n",
    "            \n",
    "            for hetatm_res in protein[chain]['hetatm_residues']:\n",
    "                hetatmres_dict = protein[chain]['hetatm_residues'][hetatm_res]\n",
    "\n",
    "                # Append the coords of the residue to the protein_atomcoords\n",
    "                protein_atomcoords = jnp.vstack((protein_atomcoords, hetatmres_dict['hetatmcoords']))\n",
    "\n",
    "                res_list.append((residue_idx, hetatmres_dict['resname']))\n",
    "\n",
    "                memb = [residue_idx for atom in hetatmres_dict['atoms']]\n",
    "                residue_memberships.extend(memb)\n",
    "\n",
    "                residue_idx +=1\n",
    "\n",
    "\n",
    "    # To do: Can we delete this? Does this ever happen?\n",
    "    # If a chain is too long to generate an ESM Embedding, skip the complex\n",
    "    if chain_too_long:\n",
    "        log_string += 'Protein AA sequence too long for ESM'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "\n",
    "    # To do: Can we delete this? Does this ever happen?\n",
    "    if not clean_aa_chain:\n",
    "        log_string += 'No clean AA_chain has been found, complex is skipped'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # COMPUTE CONNECTIVITY BETWEEN LIGAND AND PROTEIN ATOMS\n",
    "    # # -----------------------------------------------------\n",
    "    \n",
    "    # With numpy --------------------------------------------------------------------------------------------------------\n",
    "    tic = time()\n",
    "    max_len = 4\n",
    "    diff = protein_atomcoords[np.newaxis, :, :] - pos[:, np.newaxis, :]\n",
    "    pairwise_distances = np.linalg.norm(diff, axis=2)\n",
    "    close = pairwise_distances <= max_len + 1\n",
    "    \n",
    "    connections = [np.unique(np.array(residue_memberships)[np.where(row)]) for row in close]\n",
    "    np_time = time()-tic\n",
    "\n",
    "    connected_res_num = sorted(list(set([atm for l in connections for atm in l])))\n",
    "    connected_res_name = [res_list[aa-1][1] for aa in connected_res_num]\n",
    "    \n",
    "    print(connections)\n",
    "    print(connected_res_num)\n",
    "    print(connected_res_name)\n",
    "    \n",
    "    print(f'Numpy Time: {np_time}')\n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # With JAX --------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Warm up the JIT compilation\n",
    "    # _ = compute_connections(np.array(protein_atomcoords), jnp.array(pos))\n",
    "    \n",
    "    # tic = time()\n",
    "    # close = compute_connections(protein_atomcoords, pos)    \n",
    "    # connections = [np.unique(np.array(residue_memberships)[np.where(row)]) for row in np.array(close)]\n",
    "    # jnp_time = time()-tic\n",
    "    # connected_res_num = sorted(list(set([atm for l in connections for atm in l])))\n",
    "    # connected_res_name = [res_list[aa-1][1] for aa in connected_res_num]\n",
    "\n",
    "    # print(f'JaxNumpy Time: {jnp_time}')\n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    unknown_res = [(res not in known_residues and res.strip('0123456789') not in known_residues) for res in connected_res_name]\n",
    "    if any(unknown_res):\n",
    "        log_string += 'Ligand has been connected to a unknown protein residue, the complex is therefore skipped'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # EXPORT DATA \n",
    "    # -------------------------------------------------------\n",
    "    import pickle\n",
    "\n",
    "    # Export protein dictionary as pkl\n",
    "    filepath = os.path.join(data_dir, f'{protein_id}_protein_dict.pkl')\n",
    "    with open(filepath, 'wb') as fp:\n",
    "        pickle.dump(protein, fp)\n",
    "\n",
    "    # Export CONNECTIONS as dict\n",
    "    connections_dict = {'connections':connections, 'res_num':connected_res_num, 'res_name':connected_res_name}\n",
    "    filepath = os.path.join(data_dir, f'{protein_id}_connections.pkl')\n",
    "    with open(filepath, 'wb') as fp:\n",
    "        pickle.dump(connections_dict, fp)\n",
    "\n",
    "\n",
    "    log_string += 'Successful'\n",
    "    log.write(log_string + \"\\n\")\n",
    "\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# GENERATE INTERACTION-GRAPHS OF ALL COMPLEXES\n",
    "#------------------------------------------------------------------------------------------------------------- \n",
    "\n",
    "# Choose the esm embedding that should be used:\n",
    "embedding_descriptor = args.embedding\n",
    "num_atomfeatures = 40\n",
    "num_edgefeatures = 17\n",
    "output_folder = f'/data/grbv/PDBbind/DTI_5/input_graphs_{embedding_descriptor}_unpad/'\n",
    "\n",
    "\n",
    "# GET THE PREPROCESSED DATA\n",
    "# -------------------------------------------------------------------------------\n",
    "# Generate a lists of all protein-ligand complexes, the corresponding folder path and protein_dictionary paths\n",
    "input_data_dir = '/data/grbv/PDBbind/DTI5_input_data_processed'\n",
    "complexes = [subfolder for subfolder in os.listdir(input_data_dir) if len(subfolder) ==4 and subfolder[0].isdigit()]\n",
    "folder_paths = [os.path.join(input_data_dir, complex) for complex in complexes]\n",
    "protein_paths = [os.path.join(folder_path, f'{complex}_protein_dict.pkl') for complex, folder_path in zip(complexes, folder_paths)]\n",
    "ligand_paths = [os.path.join(folder_path, f'{complex}_ligand_san.sdf') for complex, folder_path in zip(complexes, folder_paths)]\n",
    "affinity_dict = load_object('/data/grbv/PDBbind/DTI5_general_affinity_dict.pkl')\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# CHECK WHICH COMPLEXES ARE PART OF THE TEST DATASETS (CASF2013 and CASF2016) AND WHICH ARE PART OF REFINED SET\n",
    "# -------------------------------------------------------------------------------\n",
    "casf_2013_dir = '/data/grbv/PDBbind/raw_data/CASF-2013/coreset'\n",
    "casf_2016_dir = '/data/grbv/PDBbind/raw_data/CASF-2016/coreset'\n",
    "\n",
    "\n",
    "\n",
    "casf_2013_complexes = [subfolder for subfolder in os.listdir(casf_2013_dir) if len(subfolder) ==4 and subfolder[0].isdigit()]\n",
    "casf_2016_complexes = [subfolder for subfolder in os.listdir(casf_2016_dir) if len(subfolder) ==4 and subfolder[0].isdigit()]\n",
    "\n",
    "data_dir_general = '/data/grbv/PDBbind/raw_data/v2020_general_san'\n",
    "data_dir_refined = '/data/grbv/PDBbind/raw_data/v2020_refined_san'\n",
    "\n",
    "general_complexes = [protein for protein in os.listdir(data_dir_general) if len(protein)==4 and protein[0].isdigit()]\n",
    "refined_complexes = [protein for protein in os.listdir(data_dir_refined) if len(protein)==4 and protein[0].isdigit()]\n",
    "\n",
    "\n",
    "# Are all 2013 complexes present in the preprocessed data? \n",
    "missing_2013 = []\n",
    "for complex in casf_2013_complexes: \n",
    "    if not complex in complexes: missing_2013.append(complex)\n",
    "print(f'CASF-2013 complexes that are not present in preprocessed data: {missing_2013}')\n",
    "\n",
    "# Are all 2016 complexes present in the preprocessed data? \n",
    "missing_2016 = []\n",
    "for complex in casf_2016_complexes: \n",
    "    if not complex in complexes: missing_2016.append(complex)\n",
    "print(f'CASF-2016 complexes that are not present in preprocessed data: {missing_2016}')\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Create Output Folders\n",
    "# -----------------------------------------------------------\n",
    "train_folder = os.path.join(output_folder, 'training_data')\n",
    "test_folder = os.path.join(output_folder, 'test_data')\n",
    "casf2013_folder = os.path.join(test_folder, 'casf2013')\n",
    "casf2016_folder = os.path.join(test_folder, 'casf2016')\n",
    "\n",
    "for folder in [train_folder, test_folder, casf2013_folder, casf2016_folder]:\n",
    "    if not os.path.exists(folder): os.makedirs(folder)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Initialize Log:\n",
    "# -------------------------------------------------------------------------------\n",
    "log_folder = output_folder + '.logs/'\n",
    "\n",
    "if not os.path.exists(log_folder): os.makedirs(log_folder)\n",
    "log_file_path = os.path.join(log_folder, f\"graph_generation_{embedding_descriptor}.txt\")\n",
    "log = open(log_file_path, 'a')\n",
    "log.write(\"Generation of Featurized Interaction Graphs - Log File:\\n\")\n",
    "log.write(\"Data: PDBbind v2020 refined and general set merged\\n\")\n",
    "log.write(\"\\n\")\n",
    "\n",
    "skipped = []\n",
    "num_threads = torch.get_num_threads() // 4\n",
    "torch.set_num_threads(num_threads)\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Here start a loop over the mutants\n",
    "#----------------------------------------------------------\n",
    "# ind = complexes.index('1a0q')\n",
    "# for complex_id, folder_path, protein_path, ligand_path in zip(complexes[ind:ind+1], folder_paths[ind:ind+1], protein_paths[ind:ind+1], ligand_paths[ind:ind+1]):\n",
    "\n",
    "for complex_id, folder_path, protein_path, ligand_path in zip(complexes, folder_paths, protein_paths, ligand_paths):\n",
    "    \n",
    "    log_string = f'{complex_id}: '\n",
    "    print(complex_id)\n",
    "\n",
    "    # Load necessary data\n",
    "    protein_dict = load_object(protein_path)\n",
    "    ligand = parse_sdf_file(ligand_path)\n",
    "\n",
    "    try:\n",
    "        connections_dict = load_object( os.path.join(folder_path, f'{complex_id}_connections.pkl') )\n",
    "    except FileNotFoundError:\n",
    "        log_string += 'Skipped - No connections_dict found (Fail in preprocessing)'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "    \n",
    "\n",
    "\n",
    "    aa_embedding = torch.load(os.path.join(folder_path, f'{complex_id}_{embedding_descriptor}.pt'))\n",
    "    aa_emb_len = aa_embedding.shape[1]\n",
    "    \n",
    "\n",
    "    # Access the ligand mol object and generate coordinate matrix (pos)\n",
    "    if not len(ligand) == 1:\n",
    "        log_string += 'Skipped - More than one ligand molecule provided'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "    \n",
    "    mol = ligand[0]\n",
    "    conformer = mol.GetConformer()\n",
    "    coordinates = conformer.GetPositions()\n",
    "    pos = np.array(coordinates)\n",
    "\n",
    "\n",
    "\n",
    "    #===================================================================================================================================\n",
    "    # Create Interaction Graph\n",
    "    #===================================================================================================================================\n",
    "\n",
    "\n",
    "    # Edge Index and Node Feature Matrix for Substrate\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    x_lig_emb = atom_features(mol, padding_len=aa_emb_len)\n",
    "    x_lig_aa = atom_features(mol, padding_len=len(amino_acids))\n",
    "    \n",
    "\n",
    "    if np.sum(np.isnan(x_lig_emb)) > 0:\n",
    "        log_string += 'Skipped - Nans during ligand feature computation'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "    \n",
    "    edge_index_lig, edge_attr_lig = edge_index_and_attr(mol, pos, self_loops=False, undirected=False)\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Add the data of the amino acids identified as neighbors to X and POS\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    connections = connections_dict['connections']\n",
    "    connections_res_num = connections_dict['res_num']\n",
    "    connections_res_name = connections_dict['res_name']\n",
    "\n",
    "    # Joined Residues Dictionary\n",
    "    protein = {}\n",
    "    residue_idx = 1\n",
    "    for chain in protein_dict:\n",
    "        chain_comp = protein_dict[chain]['composition']\n",
    "\n",
    "        if chain_comp == [True, False] or chain_comp == [True, True]:\n",
    "            for residue in protein_dict[chain]['aa_residues']:\n",
    "                protein[residue_idx] = protein_dict[chain]['aa_residues'][residue]\n",
    "                residue_idx += 1\n",
    "\n",
    "        elif chain_comp == [False, True]:\n",
    "            for hetatm_res in protein_dict[chain]['hetatm_residues']:\n",
    "                protein[residue_idx] = protein_dict[chain]['hetatm_residues'][hetatm_res]\n",
    "                residue_idx += 1\n",
    "\n",
    "    # Iterate over the connection enzyme residues\n",
    "    x_prot_emb = np.array([]).reshape(0, aa_emb_len + num_atomfeatures)\n",
    "    x_prot_aa = np.array([]).reshape(0, len(amino_acids) + num_atomfeatures)\n",
    "    \n",
    "    new_indeces = []\n",
    "    count = pos.shape[0]\n",
    "    residue_mismatch = False\n",
    "    incomplete_residue = False\n",
    "\n",
    "    for residue, resname in zip(connections_res_num, connections_res_name):\n",
    "\n",
    "        if not resname == protein[residue]['resname']:\n",
    "            print(f'Complex {complex_id}: Residues do not match with')\n",
    "            residue_mismatch = True\n",
    "        \n",
    "        # IF THE RESIDUE IS AN AMINO ACID\n",
    "        if resname in amino_acids:\n",
    "            \n",
    "            try: ca_idx = protein[residue]['atoms'].index('CA')\n",
    "            except ValueError as ve: \n",
    "                incomplete_residue = (residue, resname)\n",
    "                continue\n",
    "            \n",
    "            # Add coords of the CA atom to pos\n",
    "            coords = protein[residue]['coords'][ca_idx]\n",
    "            pos = np.vstack((pos, coords))\n",
    "\n",
    "\n",
    "            # Add feature vector to prot_emb matrix\n",
    "            padding = np.zeros((1, num_atomfeatures))\n",
    "            embedding = aa_embedding[residue-1]\n",
    "            features = np.concatenate((embedding[np.newaxis,:], padding), axis=1)\n",
    "            # ----------------------------------------------\n",
    "            x_prot_emb = np.vstack((x_prot_emb, features))\n",
    "            # ----------------------------------------------\n",
    "\n",
    "\n",
    "            # Add feature vector to prot_aa matrix\n",
    "            padding = np.zeros((1, num_atomfeatures))\n",
    "            aa_identity = one_of_k_encoding_unk(resname, amino_acids)\n",
    "            features = np.concatenate((np.array(aa_identity)[np.newaxis,:], padding), axis=1)\n",
    "            # ----------------------------------------------\n",
    "            x_prot_aa = np.vstack((x_prot_aa, features))\n",
    "            # ----------------------------------------------\n",
    "            \n",
    "\n",
    "        # IF THE RESIDUE IS A HETATM\n",
    "        else:\n",
    "            # Add coords of hetatm to pos\n",
    "            coords = protein[residue]['hetatmcoords']\n",
    "            pos = np.vstack((pos, coords))\n",
    "\n",
    "            # Add feature vector of hetatm to x\n",
    "            resname_smiles = hetatm_smiles_dict1[resname.strip('0123456789')]\n",
    "            hetatm_mol = Chem.MolFromSmiles(resname_smiles)\n",
    "\n",
    "            hetatm_features_emb = atom_features(hetatm_mol, padding_len=aa_emb_len)\n",
    "            hetatm_features_aa = atom_features(hetatm_mol, padding_len=len(amino_acids))\n",
    "\n",
    "            # ----------------------------------------------\n",
    "            x_prot_emb = np.vstack((x_prot_emb, hetatm_features_emb))\n",
    "            x_prot_aa = np.vstack((x_prot_aa, hetatm_features_aa))\n",
    "            # ----------------------------------------------\n",
    "\n",
    "        new_indeces.append(count)\n",
    "        count +=1\n",
    "\n",
    "\n",
    "    # MASTER NODE\n",
    "    # add master node features (ones) to x_prot and add a point with mean of ligand coordinates to pos\n",
    "\n",
    "    master_node_features_emb = np.zeros([1, aa_emb_len + num_atomfeatures], dtype=np.float64)\n",
    "    master_node_features_aa = np.zeros([1, len(amino_acids) + num_atomfeatures], dtype=np.float64)\n",
    "\n",
    "\n",
    "    x_prot_aa = np.vstack((x_prot_aa, master_node_features_aa))\n",
    "    x_prot_emb = np.vstack((x_prot_emb, master_node_features_emb))\n",
    "\n",
    "    pos = np.vstack((pos, np.mean(pos[:x_lig_emb.shape[0],:], axis=0)))\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Check that no nans have been added to x during the feature computation\n",
    "    if np.sum(np.isnan(x_prot_emb)) > 0 or np.sum(np.isnan(x_prot_aa)) > 0:\n",
    "        log_string += 'Skipped - Nans during enzyme residues feature computation'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "\n",
    "    # Check that there has been no residue mismatch\n",
    "    if residue_mismatch: \n",
    "        log_string += 'Skipped - Mismatch between \"connections\" and protein_dict found!'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "    \n",
    "    # If in one of the residues the CA atom was not found, PDB is incomplete, skip complex\n",
    "    if incomplete_residue:\n",
    "        log_string += f'Skipped - Protein residue {incomplete_residue} missing CA-Atom'\n",
    "        log.write(log_string + \"\\n\")\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EDGE INDEX, EDGE ATTR - Add the connection identified above to the edge_index\n",
    "    #------------------------------------------------------------------------------------------\n",
    "\n",
    "    mapping = {key: value for key, value in zip(connections_res_num, new_indeces)}\n",
    "\n",
    "    edge_index_prot = [[],[]]\n",
    "    edge_attr_prot = []\n",
    "\n",
    "    for index, neighbor_list in enumerate(connections): \n",
    "        for enzyme_residue in neighbor_list:\n",
    "            \n",
    "            edge_index_prot[0]+=[index]\n",
    "            edge_index_prot[1]+=[mapping[enzyme_residue]]\n",
    "\n",
    "            distance = np.linalg.norm(pos[index]-pos[mapping[enzyme_residue]])\n",
    "\n",
    "            # Add the feature vector of the new edges to new_edge_attr (2x)\n",
    "            non_cov_feature_vec =   [0.,0.,1.,                # non-covalent interaction\n",
    "                                    distance/10,              # length divided by 10\n",
    "                                    0.,0.,0.,0.,0.,           # bondtype = non-covalent\n",
    "                                    0.,                       # is not conjugated\n",
    "                                    0.,                       # is not in ring\n",
    "                                    0.,0.,0.,0.,0.,0.]        # No stereo -> non-covalent\n",
    "\n",
    "            # Add the feature vector of the new edges to new_edge_attr\n",
    "            edge_attr_prot.append(non_cov_feature_vec)\n",
    "\n",
    "    edge_index_prot = torch.tensor(edge_index_prot, dtype=torch.int64)\n",
    "    edge_attr_prot = torch.tensor(edge_attr_prot, dtype=torch.float64)\n",
    "    #------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Merging the two edge_indeces and edge_attrs into an overall edge_index and edge_attr\n",
    "    edge_index = torch.concatenate( [edge_index_lig, edge_index_prot], axis=1 )\n",
    "    edge_attr = torch.concatenate( [edge_attr_lig, edge_attr_prot], axis=0 )\n",
    "\n",
    "\n",
    "    # Make undirected and add remaining self-loops\n",
    "    edge_index, edge_attr = make_undirected_with_self_loops(edge_index, edge_attr)\n",
    "    edge_index_prot, edge_attr_prot = make_undirected_with_self_loops(edge_index_prot, edge_attr_prot)\n",
    "    edge_index_lig, edge_attr_lig = make_undirected_with_self_loops(edge_index_lig, edge_attr_lig)\n",
    "\n",
    "    # Master Node edge index. Connect all nodes to a hypothetical master node in a directed way\n",
    "    # (information flows only from the ligand nodes into the master node)\n",
    "    n_normal_nodes = x_lig_emb.shape[0] + x_prot_emb.shape[0] - 1 \n",
    "    \n",
    "    master_lig = [[i for i in range(x_lig_emb.shape[0])],\n",
    "                  [n_normal_nodes for _ in range(x_lig_emb.shape[0])]]\n",
    "    \n",
    "    master_prot = [[i for i in range(max(master_lig[0])+1, n_normal_nodes)],\n",
    "                   [n_normal_nodes for _ in range(x_prot_emb.shape[0]-1)]]\n",
    "\n",
    "    edge_index_master_lig = torch.tensor(master_lig, dtype=torch.int64)\n",
    "    edge_index_master_prot = torch.tensor(master_prot, dtype=torch.int64)\n",
    "\n",
    "\n",
    "    # Check the shapes of the input tensors\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    shape_inconsistency = False\n",
    "\n",
    "    try:\n",
    "        if pos.shape[1] != 3:\n",
    "            log_string += f'Skipped - POS has shape {pos.shape}'\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_lig_emb.shape[1] != num_atomfeatures+aa_emb_len:\n",
    "            log_string += f'Skipped - x_lig_emb has shape {x_lig_emb.shape}'\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_lig_aa.shape[1] != num_atomfeatures+len(amino_acids):\n",
    "            log_string += f'Skipped - x_lig_aa has shape {x_lig_aa.shape}'\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_prot_emb.shape[1] != aa_emb_len + num_atomfeatures:\n",
    "            log_string += f'Skipped - x_prot_emb has shape {x_prot_emb.shape}'\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_prot_aa.shape[1] != len(amino_acids) + num_atomfeatures:\n",
    "            log_string += f'Skipped - x_prot_aa has shape {x_prot_aa.shape}'\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_prot_aa.shape[0] != x_prot_emb.shape[0]:\n",
    "            log_string += f'Skipped - Dimension 0 of x_prot_emb {x_prot_aa.shape} and x_prot_aa {x_prot_aa.shape} not identical '\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "\n",
    "        if x_prot_aa.shape[0] + x_lig_emb.shape[0] != pos.shape[0]:\n",
    "            log_string += f'Skipped - x_lig_emb {x_prot_aa.shape} and x_prot {x_prot_aa.shape} not consistent with POS {pos.shape} '\n",
    "            log.write(log_string + \"\\n\")\n",
    "            skipped.append(complex_id)\n",
    "            continue\n",
    "        \n",
    "        for edge_ind, edge_at in [(edge_index.shape, edge_attr.shape),(edge_index_lig.shape, edge_attr_lig.shape),(edge_index_prot.shape, edge_attr_prot.shape)]:\n",
    "            if edge_ind[0] != 2 or edge_at[1] != num_edgefeatures or edge_ind[1]!=edge_at[0]:\n",
    "                log_string += f'Skipped - edge indeces error: \\\n",
    "                        {edge_index.shape, edge_attr.shape}\\n\\\n",
    "                        {edge_index_lig.shape, edge_attr_lig.shape}\\n\\\n",
    "                        {edge_index_prot.shape, edge_attr_prot.shape}'\n",
    "                log.write(log_string + \"\\n\")\n",
    "                shape_inconsistency = True\n",
    "\n",
    "    except IndexError as e:\n",
    "        log_string += 'Skipped -' + str(e)\n",
    "        log.write(log_string + \"\\n\")\n",
    "        shape_inconsistency = True\n",
    "            \n",
    "    if shape_inconsistency:\n",
    "        skipped.append(complex_id)\n",
    "        continue\n",
    "    #------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Retrieve the binding affinity and other metadata of the complex\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    affmetric_encoding = {'Ki':1., 'Kd':2.,'IC50':3.}\n",
    "    precision_encoding = {'=':0., '>':1., '<':2., '>=':3., '<=':4., '~':5.}\n",
    "   \n",
    "    if 'Ki' in affinity_dict[complex_id].keys():\n",
    "        affinity = affinity_dict[complex_id]['Ki']\n",
    "        affinity_metric = 'Ki'\n",
    "        \n",
    "    elif 'Kd' in affinity_dict[complex_id].keys():\n",
    "        affinity = affinity_dict[complex_id]['Kd']\n",
    "        affinity_metric = 'Kd'\n",
    "\n",
    "    elif 'IC50' in affinity_dict[complex_id].keys():\n",
    "        affinity = affinity_dict[complex_id]['IC50']\n",
    "        affinity_metric = 'IC50'\n",
    "\n",
    "    resolution = affinity_dict[complex_id]['resolution']\n",
    "    log_kd_ki = affinity_dict[complex_id]['log_kd_ki']\n",
    "    precision = affinity_dict[complex_id]['precision']\n",
    "\n",
    "\n",
    "    try: resolution = float(resolution)\n",
    "    except ValueError: resolution = 0\n",
    "\n",
    "\n",
    "\n",
    "    # Find out if the graph is part of the test or training data and save into the corresponding folder: \n",
    "    # -------------------------------------------------------------------------------------------\n",
    "\n",
    "    log_string += 'Successful - Saved in '\n",
    "    save_folders = []\n",
    "\n",
    "    in_casf_2013 = False\n",
    "    in_casf_2016 = False\n",
    "    in_refined = False\n",
    "\n",
    "    if complex_id in casf_2013_complexes:\n",
    "        in_casf_2013 = True\n",
    "        log_string += 'CASF2013 '\n",
    "        save_folders.append(casf2013_folder)\n",
    "        \n",
    "    if complex_id in casf_2016_complexes:\n",
    "        in_casf_2016 = True\n",
    "        log_string += 'CASF2016 '\n",
    "        save_folders.append(casf2016_folder)\n",
    "\n",
    "    if (not in_casf_2013) and (not in_casf_2016):\n",
    "        log_string += 'Training Data'\n",
    "        save_folders.append(train_folder)\n",
    "        in_refined = complex_id in refined_complexes\n",
    "\n",
    "\n",
    "\n",
    "    metadata = [in_refined, affmetric_encoding[affinity_metric], resolution, precision_encoding[precision], float(log_kd_ki)]\n",
    "    \n",
    "    graph = Data(\n",
    "        \n",
    "            x_lig_emb = torch.tensor(x_lig_emb, dtype=torch.float64),\n",
    "            x_lig_aa = torch.tensor(x_lig_aa, dtype=torch.float64),\n",
    "\n",
    "            x_prot_emb = torch.tensor(x_prot_emb, dtype=torch.float64),\n",
    "            x_prot_aa = torch.tensor(x_prot_aa, dtype=torch.float64),\n",
    "                 \n",
    "            edge_index = edge_index,\n",
    "            edge_index_lig = edge_index_lig,\n",
    "            edge_index_prot = edge_index_prot,\n",
    "\n",
    "            edge_index_master_lig = edge_index_master_lig,\n",
    "            edge_index_master_prot = edge_index_master_prot,\n",
    "\n",
    "            edge_attr = edge_attr,\n",
    "            edge_attr_lig = edge_attr_lig,\n",
    "            edge_attr_prot = edge_attr_prot,\n",
    "\n",
    "            pos = torch.tensor(pos, dtype=torch.float64),\n",
    "            affinity= torch.tensor(affinity, dtype=torch.float64),\n",
    "\n",
    "            id = complex_id,\n",
    "            data = torch.tensor(metadata, dtype=torch.float64)\n",
    "            )\n",
    "    \n",
    "\n",
    "    # Save the Graph\n",
    "    for save_folder in save_folders:\n",
    "        torch.save(graph, os.path.join(save_folder, f'{complex_id}_graph_{embedding_descriptor}.pt'))\n",
    "    \n",
    "\n",
    "\n",
    "    log.write(log_string + \"\\n\")\n",
    "\n",
    "print(f'Graph Generation Finished - Skipped Complexes {skipped}')\n",
    "log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
